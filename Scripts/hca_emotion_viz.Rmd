---
title: "Untitled"
output: html_document
date: "2025-12-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Postprocessing of NLP results
```{r}
library(tidyverse)

# Prefer minimal theme, and use color from scale_color_brewer set 2 when it's present

# theme_preferences <- theme_minimal()
```

```{r}
emotion_results <- read_csv(r"(C:\Users\smert.SAMLAPTOP\OneDrive\Documents\hca-emotion\emotion_results.csv)")
# emotion_results <- read_csv("../emotion_results.csv")

# Rename the "_results" columns to remove results suffix
emotion_results <- emotion_results %>%
  rename_with(~ str_replace(., "_score", ""), ends_with("_score"))

# Create a new column for the dominant emotion based on the highest score
emotion_vals <- emotion_results[,c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")]

emotion_results$dominant_emotion <- colnames(emotion_vals)[max.col(emotion_vals)]

emotion_results <- emotion_results %>%
  mutate(dominant_emotion_value = pmax(anger, joy, sadness, fear, disgust, surprise, neutral),
         dominant_uncertainty = 1 - dominant_emotion_value)

# Add publication dates and a couple of other metadata fields (is the date an approximation? what was the original language?) from the hcandersenr package
library(hcandersenr)
emotion_results <- emotion_results %>%
  left_join(EK %>% select(date, approximate, org_language, name_en), by = c("tale" = "name_en"))

# Missings check from merge
emotion_results %>%
  summarise(
    total_tales = n(),
    missing_dates = sum(is.na(date)),
    missing_approx = sum(is.na(approximate)),
    missing_original_lang = sum(is.na(org_language)),
    # approximate_dates = sum(approximate, na.rm = TRUE)
  )

# Show a sample timeline of tales with their publication dates
emotion_results %>%
  distinct(tale, date) %>%
  arrange(date) %>%
  ggplot(aes(x = date, y = reorder(tale, date))) +
  geom_point(color = "steelblue") +
  labs(title = "Publication Timeline of HCA Tales",
       x = "Publication Date",
       y = "Tale") +
  theme_minimal()

emotion_results %>% names()

# thinking aloud: the final timeline viz on the website could be akin to this, with coloration representing "dominant" or perhaps "final dominant" emotion for each tale, and size of bubble or a different axis could represent story length/amount of chunks/amt chars/amt words/etc. another idea would be to create one "point" per year with a color representing overall dominant emotion of the entire year rather than by individual tale. so a year with 7 tales, 4 of which are predominantly joyous would be colored by joy. you could hover this and see the tales and their individual colors or timelines.
```

I already know and am imagining painting a timeline of HCA's tales. This would be an intuitive, interesting way to examine some high-level questions. During what periods of his life was he most productive in writing? Were his most famous tales all written during a particular phase? Are they similar emotionally? Did his emotional tone change over time, perhaps reflecting his personal life circumstances? Let's prepare to visualize this using D3.js later on.

```{r}
# Prepare data for timeline visualization
library(jsonlite)
library(lubridate)

# Extract just the year from your Date column
timeline_data <- emotion_results %>%
  group_by(tale, date, approximate, org_language) %>%
  summarise(
    # Extract year from Date
    year = year(date[1]),  # Use year() function from lubridate
    
    # Your existing emotion aggregations
    sadness = mean(sadness),
    joy = mean(joy),
    fear = mean(fear),
    anger = mean(anger),
    disgust = mean(disgust),
    surprise = mean(surprise),
    neutral = mean(neutral),
    
    num_chunks = n(),
    total_tokens = sum(token_count),
    
    emotion_purity = max(sadness, joy, fear, anger, disgust, surprise, neutral) - 
                     median(c(sadness, joy, fear, anger, disgust, surprise, neutral)),
    
    dominant_emotion = names(which.max(c(
      sadness = mean(sadness),
      joy = mean(joy), 
      fear = mean(fear),
      anger = mean(anger),
      disgust = mean(disgust),
      surprise = mean(surprise),
      neutral = mean(neutral)
    ))),
    
    dominant_value = max(sadness, joy, fear, anger, disgust, surprise, neutral)
  ) %>%
  ungroup()

# Now export with 'year' instead of 'date'
timeline_json <- timeline_data %>%
  select(-date) %>%  # Remove the full date
  toJSON(pretty = TRUE, auto_unbox = TRUE)

write(timeline_json, 'data/timeline_data.json')

# Verify
test <- fromJSON('data/timeline_data.json')
head(test$year)  # Should show: 1859, 1837, etc.
```


These emotion results, due to the model used, were "chunked" into segments based on their token length, as the model looks at a rolling window of text. As a result, we have multiple sets of results per tale, assuming they exceeded to maximum token allowance. A bit of an inconvenience when preparing the data, but it does let us look at smaller segments of HCA's tales and see what kinds of emotions he is primarily using in different parts of the stories.

```{r}
# Quick look at dominant emotions across all chunks. Reorder the columns from the most frequent to least frequent emotion
emotion_results %>%
  mutate(dominant_emotion = factor(dominant_emotion, levels = names(sort(table(dominant_emotion), decreasing = TRUE)))) %>%
  ggplot(aes(x = dominant_emotion, fill = dominant_emotion)) +
  geom_bar() +
  labs(title = "Dominant Emotions Across All Tale Chunks",
       x = "Dominant Emotion",
       y = "Count") +
  theme_bw() +
  scale_fill_brewer(palette = "Set2")
# 

# If we collapse each story to its dominant emotion (average across all chunks, weight by tokens)

# calculate average scores for each emotion
emotion_results %>%
  summarise(across(c(anger, joy, sadness, fear, disgust, surprise, neutral), mean)) %>%
  pivot_longer(everything(), names_to = "emotion", values_to = "average_score") %>%
  ggplot(aes(x = emotion, y = average_score, fill = emotion)) +
  geom_bar(stat = "identity") +
  labs(title = "Average Emotion Scores Across All Tale Chunks",
       x = "Emotion",
       y = "Average Score") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

```

From this, it looks like HCA employs negative emotions by and large, with "disgust", "fear", and "sadness" being the most common dominant emotions in his tale chunks. "Joy" is among the least common dominant emotions, only surpassed by "anger" and "surprise". That said, these emotions may just be the most difficult to continue to express throughout an entire "chunk" of text - surprise, for example, is often a sudden and fleeting emotion when expressed - it might make sense that this is the least (by quite a significant amount) common dominant emotion.

One question that came to my mind is, if we make an "uncertainty" metric as the inverse of the dominant emotion score, do we see any patterns in uncertainty related to token or sentence counts? What does it look like if we take the 8 "longest" tales (most chunks) and plot these metrics?
```{r}
# compare confidence to chunk size. are we more confident with larger chunks? look only at the 10 longest tales (those with the highest max value of the "chunk" variable)
longest_tales <- emotion_results %>%
  group_by(tale) %>%
  summarise(max_chunk = max(chunk)) %>%
  arrange(desc(max_chunk)) %>%
  slice_head(n = 8) %>%
  pull(tale)

emotion_results %>%
  filter(tale %in% longest_tales) %>%
  ggplot(aes(x = sentence_count, y = dominant_uncertainty, color = tale)) +
  geom_point() +
  # geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Dominant Emotion Uncertainty vs. Chunk Size for Longest Tales",
       x = "Chunk Size",
       y = "Dominant Emotion Uncertainty") +
  theme_minimal() +
  scale_color_brewer(palette = "Set2")

table(emotion_results$dominant_emotion)
?pmax

# Which dominant emotion has the least uncertainty on average?
emotion_results %>%
  group_by(dominant_emotion) %>%
  summarise(average_uncertainty = mean(dominant_uncertainty)) %>%
  arrange(average_uncertainty)

# What are dominant emotions when tales are combined, taking the average of each chunk's values per tale?
emotion_results %>%
  group_by(tale) %>%
  summarise(across(c(anger, joy, sadness, fear, disgust, surprise, neutral), mean)) %>%
  mutate(dominant_emotion = colnames(.[,c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")])[max.col(.[, c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")])]) %>%
  select(tale, dominant_emotion) %>%
  arrange(tale)


emotion_results %>% 
  filter(tale == "\"Something\"") %>%
  View()
```

# Q: Would it make sense to reduce chunk sizes? what effect would this have on: uncertainty, share of emotions like surprise/anger, etc.?
It seems like there is little to no trend in uncertainty as token count increases. Most chunks have a dominant emotion of "neutral" or "joy", with very few chunks classified as "anger", "disgust", or "surprise".

# Given the overwhelmingly "short" (relative to novels) lengths of these tales, it stands to reason that the emotions which readers associate with a given tale may be largely determined by their beginnings/endings/specific climax moments rather than the most "common" emotional responses. For example in HCA we see a lot of disgust, fear, sadness, etc. Does the same hold true of endings, or do endings have resolutions which are largely associated with joy, such that most of his stories have trials and trivulations but happy endings?

```{r}
names(emotion_results)

emotion_results %>%
  view()

# Reshape long so that we can make a ggplot of the amotional trajectory of a story across all emotions and chunks, with the emotion values on the y-axis, and the chunk progression on the x-axis
emotion_long <- emotion_results %>%
  pivot_longer(cols = c(anger, joy, sadness, fear, disgust, surprise, neutral, dominant_uncertainty), names_to = "emotion", values_to = "value")

# Examine emotional trajectories. First, let's look at a scatterplot by chunk of all emotions
plot_tale <- function(tale_name) {
  emotion_long %>%
    filter(tale == tale_name) %>%
    ggplot(.) +
      aes(x = chunk, y = value, color = emotion) +
      geom_point() +
      # geom_line() +
      geom_smooth(se = FALSE) +
      labs(title = paste("Emotional Trajectory of", tale_name),
           x = "Chunk",
           y = "Emotion Value") +
      theme_minimal() +
      scale_color_manual(values = c("sadness" = "blue",
                                  "anger" = "red",
                                  "disgust" = "orange",
                                  "dominant_uncertainty" = "black",
                                  "joy" = "green",
                                  "fear" = "purple",
                                  "surprise" = "yellow",
                                  "neutral" = "gray"))
      # scale_color_brewer(palette = "Set2")
}

plot_tale("The ugly duckling")
plot_tale("Holger Danske")

# emotion_results %>% view()
# list all tale names within emotion_results
# unique(emotion_results$tale) %>% view()

# How can i set the specific colors of each emotion in the plot above? I want sadness to be blue, anger to be red, disgust to be orange, dominant_uncertainty to be black, joy to be green, fear to be purple, surprise to be yellow, and neutral to be gray.
emotion_long %>%
  filter(tale == "The little mermaid") %>%
  ggplot(.) +
    aes(x = chunk, y = value, color = emotion) +
    geom_point() +
    geom_line() +
    labs(title = paste("Emotional Trajectory of", "The little mermaid"),
         x = "Chunk",
         y = "Emotion Value") +
    theme_minimal() +
    scale_color_manual(values = c("sadness" = "blue",
                                  "anger" = "red",
                                  "disgust" = "orange",
                                  "dominant_uncertainty" = "black",
                                  "joy" = "green",
                                  "fear" = "purple",
                                  "surprise" = "yellow",
                                  "neutral" = "gray"))

# how do you plot the values as well as the uncertainty of the dominant emotion at the same time? can you just add another y variable as long as it still fits in the same y-value range as the existing axis?
# you

```

With an ultimate goal in mind to create a network visualization with similar tales clustered together, a couple of immediate methods come to mind to featurize the emotion trajectories. 

For one, we could normalize each tale to a certain number of "snapshot" points, no matter its length. For example if we have a story which is 10 "chunks" long and another which is 30 chunks long, we could interpolate both to have 20 "points" along their emotional trajectory, allowing us to compare them directly. From there, we could calculate features such as average emotion intensity, emotional direction (slope), and variability (standard deviation) for each emotion across the normalized trajectory. These features could then be used for clustering or dimensionality reduction techniques like PCA to visualize similarities between tales.

For another, we could keep the existing chunk structure, and calculate features directly from the raw chunk data. This would involve computing summary statistics for each emotion across the chunks of a tale, such as mean intensity, maximum intensity, and standard deviation. Additionally, we could analyze the emotional "momentum" by looking at changes in emotion intensity between consecutive chunks. These features could also be used for clustering or PCA.

Let's start by testing normalization. Even within this one task, we could choose different ways. we could set all tales to the max chunk size, in effect oversampling some tales, or we could set all tales to a fixed number of points (say 20 or something close to the median) regardless of original chunk count. Let's try the latter first.

```{r}
# 1. Normalize emotional trajectories for comparison
# Create a function to interpolate all tales to the same number of "points" 
# (say, 20 points) regardless of original chunk count

# What does the median look like?
median_chunk_count <- median(emotion_results %>%
                                group_by(tale) %>%
                                summarise(chunk_count = n()) %>%
                                pull(chunk_count))

ggplot(emotion_results %>%
         group_by(tale) %>%
         summarise(chunk_count = n()),
       aes(x = chunk_count)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  geom_vline(xintercept = median_chunk_count, color = "red", linetype = "dashed") +
  labs(title = "Distribution of Chunk Counts per Tale",
       x = "Chunk Count",
       y = "Number of Tales") +
  theme_minimal()

normalize_trajectory <- function(tale_data, n_points = 5) {
  tale_chunks <- tale_data %>% arrange(chunk)
  
  # Check if tale has only 1 chunk - can't interpolate
  if(nrow(tale_chunks) == 1) {
    # Just replicate the single chunk values across all positions
    normalized <- tibble(
      position = seq(0, 1, length.out = n_points)
    )
    
    for(emotion in c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")) {
      normalized[[emotion]] <- rep(tale_chunks[[emotion]][1], n_points)
    }
    
    return(normalized)
  }
  
  # For tales with 2+ chunks, interpolate
  normalized <- tibble(
    position = seq(0, 1, length.out = n_points)
  )
  
  # Create normalized position for each chunk
  chunk_positions <- (tale_chunks$chunk) / (max(tale_chunks$chunk))
  
  for(emotion in c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")) {
    interpolated <- approx(
      x = chunk_positions,
      y = tale_chunks[[emotion]],
      xout = normalized$position
    )$y
    normalized[[emotion]] <- interpolated
  }
  
  return(normalized)
}

# Apply to all tales
normalized_trajectories <- emotion_results %>%
  group_by(tale) %>%
  group_modify(~normalize_trajectory(.x))
```

## Cluster by emotion patterns - maybe add pca?

Once we start thinking about clustering and/or networks, we can think about evaluating/featurizing them. Things like modularity, network density, clustering coefficient, centrality measures (degree, betweenness, closeness), etc. could be useful to describe the network structure. For clustering, silhouette scores, Davies-Bouldin index, or Calinski-Harabasz index could help assess cluster quality.

Another factor to think about - what kind of structures might we expect to see from this collection of tales in the first place? Some tales are truly only one "chunk" long as far as an input to the transformer - for these we have no measure of emotion trajectory, essentially just one "overall" measure of emotion. Additionally, we could expect that these stories can't explore emotions nearly as deeply as stories which span 20+ "chunks" long. So we might expect to see clusters of "short and simple" tales, "long and complex" tales, and maybe some in-between. However, in an ideal world our clustering/network will also capture tales which are similar emotionally (sad tales, happy tales, sad at first but happy endings, etc.). What can we do to capture these nuances? 

```{r}
library(cluster)
library(factoextra)

# Create feature matrix: each tale represented by its emotional trajectory
tale_features <- normalized_trajectories %>%
  group_by(tale) %>%
  summarise(across(c(anger:neutral), list(
    mean = mean,
    sd = sd,
    max = max,
    trajectory_slope = ~coef(lm(.x ~ position))[2]  # emotional direction
  )))

# K-means clustering
set.seed(831) #HCA
tale_clusters <- kmeans(select(tale_features, -tale), centers = 7)

# Add cluster labels back
tale_features$cluster <- tale_clusters$cluster

# Visualize with PCA
fviz_cluster(tale_clusters, data = select(tale_features, -tale, -cluster),
             geom = "text",
             repel = TRUE) +
  labs(title = "HCA Tales Clustered by Emotional Patterns")
```

## Narrative arc detection
```{r}
# Instead of the below, we can do a plotting of the graph trajectories using PCA. What I am imagining is that we can create a PCA plot, and the points themselves will be graphs. These graphs will show the points which fall in the local area of the PCA plot, so we can visually see the trajectories of an area rather than just a grouping of points.

# Define narrative arc patterns
detect_arc_pattern <- function(tale_traj) {
  # Calculate emotional "energy" (sum of strong emotions)
  tale_traj <- tale_traj %>%
    mutate(
      negative_energy = sadness + fear + disgust + anger,
      positive_energy = joy + surprise,
      total_energy = negative_energy + positive_energy
    )
  
  # Identify pattern type based on trajectory
  beginning <- mean(tale_traj$total_energy[1:5])
  middle <- mean(tale_traj$total_energy[8:12])
  end <- mean(tale_traj$total_energy[16:20])
  
  # Classify arc type
  if(middle > beginning & end > middle) {
    return("Rising Action")
  } else if(middle < beginning & end > beginning) {
    return("Tragedy to Triumph")  # Classic HCA!
  } else if(middle > beginning & end < beginning) {
    return("Rise and Fall")
  } else if(beginning > middle & end > beginning) {
    return("Challenge and Resolution")
  } else {
    return("Steady State")
  }
}

# Apply to all tales
arc_patterns <- normalized_trajectories %>%
  group_by(tale) %>%
  group_modify(~tibble(arc_pattern = detect_arc_pattern(.x)))
```

## Shiny dashboard
```{r}
library(shiny)
library(plotly)
library(shinydashboard)

ui <- dashboardPage(
  dashboardHeader(title = "HCA Emotional Analysis"),
  
  dashboardSidebar(
    sidebarMenu(
      menuItem("Tale Explorer", tabName = "explorer"),
      menuItem("Tale Comparison", tabName = "comparison"),
      menuItem("Clustering Analysis", tabName = "clusters"),
      menuItem("Recommender", tabName = "recommender")
    )
  ),
  
  dashboardBody(
    tabItems(
      # Tale Explorer Tab
      tabItem(
        tabName = "explorer",
        fluidRow(
          box(
            width = 4,
            selectInput("selected_tale", "Choose a Tale:",
                       choices = unique(emotion_results$tale))
          ),
          box(
            width = 8,
            plotlyOutput("emotional_trajectory", height = 400)
          )
        ),
        fluidRow(
          box(
            width = 6,
            plotlyOutput("emotion_breakdown")
          ),
          box(
            width = 6,
            valueBoxOutput("dominant_emotion_box"),
            verbatimTextOutput("tale_summary")
          )
        )
      ),
      
      # Comparison Tab
      tabItem(
        tabName = "comparison",
        fluidRow(
          box(
            width = 3,
            selectInput("tale1", "Tale 1:", choices = unique(emotion_results$tale)),
            selectInput("tale2", "Tale 2:", choices = unique(emotion_results$tale))
          ),
          box(
            width = 9,
            plotlyOutput("comparison_plot", height = 500)
          )
        )
      ),
      
      # Clustering Tab
      tabItem(
        tabName = "clusters",
        fluidRow(
          box(
            width = 12,
            plotlyOutput("cluster_viz", height = 600)
          )
        ),
        fluidRow(
          box(
            width = 12,
            DT::dataTableOutput("cluster_tales")
          )
        )
      ),
      
      # Recommender Tab
      tabItem(
        tabName = "recommender",
        fluidRow(
          box(
            width = 4,
            selectInput("favorite_tale", "Your Favorite Tale:",
                       choices = unique(emotion_results$tale)),
            actionButton("recommend", "Get Recommendations", 
                        class = "btn-primary")
          ),
          box(
            width = 8,
            h3("Recommended Tales Based on Emotional Similarity"),
            DT::dataTableOutput("recommendations")
          )
        )
      )
    )
  )
)

server <- function(input, output, session) {
  # Emotional trajectory plot
  output$emotional_trajectory <- renderPlotly({
    tale_data <- emotion_long %>%
      filter(tale == input$selected_tale)
    
    plot_ly(tale_data, x = ~chunk, y = ~value, color = ~emotion,
            type = 'scatter', mode = 'lines+markers',
            colors = c("sadness" = "blue", "anger" = "red", 
                      "disgust" = "orange", "joy" = "green",
                      "fear" = "purple", "surprise" = "yellow",
                      "neutral" = "gray")) %>%
      layout(title = paste("Emotional Journey:", input$selected_tale),
             xaxis = list(title = "Story Progression"),
             yaxis = list(title = "Emotion Intensity"))
  })
  
  # ... more server logic for other features
}

shinyApp(ui, server)
```

# Recommender system
```{r}
# Calculate tale similarity based on emotional profiles
library(proxy)

# Create tale-by-emotion matrix
tale_emotion_matrix <- normalized_trajectories %>%
  group_by(tale) %>%
  summarise(across(anger:neutral, mean)) %>%
  column_to_rownames("tale")

# Calculate cosine similarity between all tales
similarity_matrix <- as.matrix(simil(tale_emotion_matrix, method = "cosine"))

# Recommender function
recommend_tales <- function(favorite_tale, n_recommendations = 5) {
  similarities <- similarity_matrix[favorite_tale, ]
  similarities <- similarities[names(similarities) != favorite_tale]
  
  top_matches <- sort(similarities, decreasing = TRUE)[1:n_recommendations]
  
  tibble(
    recommended_tale = names(top_matches),
    similarity_score = round(top_matches, 3),
    reason = "Similar emotional trajectory and intensity patterns"
  )
}

# Test it
recommend_tales("The ugly duckling")
```

# SQL integration database layer
```{r}
library(DBI)
library(RSQLite)

# Create SQLite database
con <- dbConnect(SQLite(), "hca_emotions.db")

# Write tables
dbWriteTable(con, "emotion_scores", emotion_results, overwrite = TRUE)
dbWriteTable(con, "normalized_trajectories", normalized_trajectories, overwrite = TRUE)
dbWriteTable(con, "tale_clusters", tale_features, overwrite = TRUE)

# Create indexes for performance
dbExecute(con, "CREATE INDEX idx_tale ON emotion_scores(tale)")
dbExecute(con, "CREATE INDEX idx_chunk ON emotion_scores(chunk)")

# Example complex queries to demonstrate SQL skills
query_top_emotional_tales <- "
  SELECT tale, 
         AVG(anger + fear + sadness + disgust) as avg_negative_emotion,
         COUNT(*) as chunk_count
  FROM emotion_scores
  GROUP BY tale
  HAVING chunk_count > 5
  ORDER BY avg_negative_emotion DESC
  LIMIT 10
"

dbGetQuery(con, query_top_emotional_tales)

# Window function example
query_emotional_momentum <- "
  SELECT tale, chunk,
         sadness,
         LAG(sadness) OVER (PARTITION BY tale ORDER BY chunk) as prev_sadness,
         sadness - LAG(sadness) OVER (PARTITION BY tale ORDER BY chunk) as sadness_change
  FROM emotion_scores
  ORDER BY tale, chunk
"

dbGetQuery(con, query_emotional_momentum)
```

## Heatmap of emotional patterns
```{r}
library(pheatmap)

# Create heatmap showing all tales' emotional profiles
tale_emotion_summary <- emotion_results %>%
  group_by(tale) %>%
  summarise(across(anger:neutral, mean)) %>%
  column_to_rownames("tale")

pheatmap(tale_emotion_summary,
         scale = "column",
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         color = colorRampPalette(c("navy", "white", "firebrick3"))(50),
         main = "HCA Tales: Emotional Heatmap")
```

## Network viz
```{r}
library(igraph)
library(ggraph)

# Create network where tales are connected if similarity > threshold
threshold <- 0.7
edge_list <- which(similarity_matrix > threshold & 
                  similarity_matrix < 1, arr.ind = TRUE)

edges <- data.frame(
  from = rownames(similarity_matrix)[edge_list[,1]],
  to = colnames(similarity_matrix)[edge_list[,2]],
  weight = similarity_matrix[edge_list]
)

# Create graph
tale_network <- graph_from_data_frame(edges, directed = FALSE)

# Add cluster membership as node attribute
V(tale_network)$cluster <- tale_features$cluster[match(V(tale_network)$name, 
                                                       tale_features$tale)]

# Visualize
ggraph(tale_network, layout = 'fr') +
  geom_edge_link(aes(alpha = weight), show.legend = FALSE) +
  geom_node_point(aes(color = factor(cluster)), size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, size = 3) +
  theme_graph() +
  labs(title = "HCA Tale Network: Emotional Similarity Connections",
       color = "Tale Cluster")
```

12/16/25:

When working with the timeline, one of the first things you can see is that the majority of tales are classified as majority "disgust". Maybe not the most prominent emotion you'd expect from a notorious fairy tale writer. Maybe not everything is sunshine and rainbows! Let's dig into this a little deeper numerically.

```{r}
# Check dominant emotion distribution
emotion_results %>%
  group_by(tale) %>%
  slice(1) %>%  # One row per tale
  count(dominant_emotion, sort = TRUE) %>%
  mutate(percentage = n / sum(n) * 100)

# Check if disgust is really dominant or just slightly ahead
tale_emotions <- emotion_results %>%
  group_by(tale) %>%
  summarise(
    across(c(anger, joy, sadness, fear, disgust, surprise, neutral), mean),
    dominant = names(which.max(c(anger[1], joy[1], sadness[1], fear[1], 
                                  disgust[1], surprise[1], neutral[1])))
  )

# How much higher is disgust than second place?
tale_emotions %>%
  rowwise() %>%
  mutate(
    disgust_margin = disgust - max(anger, joy, sadness, fear, surprise, neutral, -disgust)
  ) %>%
  filter(dominant == "disgust") %>%
  summarise(
    median_margin = median(disgust_margin),
    mean_margin = mean(disgust_margin)
  )

# What are some high-disgust tales?
tale_emotions %>%
  filter(dominant == "disgust") %>%
  arrange(desc(disgust)) %>%
  select(tale, disgust, joy, sadness, fear) %>%
  head(10)
```

## Most Likely Explanations

### 1. **Model Training Bias** (Most Likely)

DistilRoBERTa was trained on **modern text** (likely Twitter, Reddit, product reviews). Fairy tale language from the 1800s is **out of distribution**:

**What triggers "disgust" in modern text:**
- Gross/unpleasant descriptions
- Moral outrage
- Negative physical descriptions
- Criticism/condemnation

**What's common in HCA tales:**
- Physical transformations ("her feet felt like knives")
- Suffering descriptions ("starving child")
- Moral lessons about vanity/cruelty
- Gothic imagery (witches, death, decay)

**The model might be confusing:**
- Fairy tale darkness → disgust
- Moral judgment language → disgust  
- Archaic negative descriptions → disgust

### 2. **Fairy Tale Genre Characteristics**

HCA tales often include:

"The Little Mermaid": Pain, transformation, sacrifice
"The Little Match Girl": Freezing, starvation, death
"The Red Shoes": Feet cut off, punishment
"The Ugly Duckling": Bullying, rejection, suffering

How are his tales distributed throughout his publishing history? For example, maybe we can explore emotion over time at a high level by showing a stream or river or flow graph of shorts, showing dominant emotion as a percentage of tales published each year.

```{r}
# Check tales per year
publishing_distribution <- timeline_data %>%
  distinct(tale, year) %>%
  count(year, sort = TRUE)

# Summary stats
publishing_distribution %>%
  summarise(
    mean_per_year = mean(n),
    median_per_year = median(n),
    max_year = year[which.max(n)],
    max_tales = max(n),
    years_with_5plus = sum(n >= 5),
    tales_in_5plus_years = sum(n[n >= 5]),
    total_tales = sum(n),
    pct_in_productive_years = 100 * sum(n[n >= 5]) / sum(n)
  )

# Visualize distribution
library(ggplot2)

ggplot(publishing_distribution, aes(x = year, y = n)) +
  geom_col(fill = "#4A90E2", alpha = 0.8) +
  geom_hline(yintercept = 3, linetype = "dashed", color = "red") +
  labs(
    title = "Tales Published Per Year",
    subtitle = "Red line shows threshold of 3+ tales",
    x = "Year", 
    y = "Number of Tales"
  ) +
  theme_minimal()

# Check emotion distribution by year
emotion_by_year <- timeline_data %>%
  distinct(tale, year, dominant_emotion) %>%
  count(year, dominant_emotion) %>%
  group_by(year) %>%
  mutate(
    total_that_year = sum(n),
    percentage = n / total_that_year * 100
  ) %>%
  arrange(year, desc(percentage))

# Show productive years
emotion_by_year %>%
  filter(total_that_year >= 5) %>%
  arrange(year, desc(percentage)) %>% view()

library(tidyverse)

# Create the base data for ALL visualizations
emotion_by_year <- timeline_data %>%
  distinct(tale, year, dominant_emotion) %>%
  count(year, dominant_emotion) %>%
  group_by(year) %>%
  mutate(
    total_tales = sum(n),
    percentage = n / sum(n) * 100
  ) %>%
  ungroup()

# Check distribution
publishing_summary <- emotion_by_year %>%
  group_by(year) %>%
  summarise(total_tales = first(total_tales)) %>%
  arrange(desc(total_tales))

print(publishing_summary)

# Summary statistics
cat("\n=== PUBLISHING PATTERN ===\n")
cat("Total years with tales:", n_distinct(emotion_by_year$year), "\n")
cat("Years with 5+ tales:", sum(publishing_summary$total_tales >= 5), "\n")
cat("Most productive year:", publishing_summary$year[1], 
    "with", publishing_summary$total_tales[1], "tales\n")
cat("Median tales/year:", median(publishing_summary$total_tales), "\n")

# Define emotion colors
emotion_colors <- c(
  sadness = '#4A90E2',
  joy = '#7ED321',
  anger = '#D0021B',
  fear = '#9013FE',
  disgust = '#F5A623',
  surprise = '#F8E71C',
  neutral = '#9B9B9B'
)

# Works with any data density
ggplot(emotion_by_year, aes(x = year, y = percentage, fill = dominant_emotion)) +
  geom_area(alpha = 0.8) +
  scale_fill_manual(values = emotion_colors) +
  labs(
    title = "Emotional Composition of Andersen's Tales Over Time",
    subtitle = "Percentage of tales by dominant emotion",
    x = "Year",
    y = "Percentage of Tales (%)",
    fill = "Dominant Emotion"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

ggsave("emotion_area_chart.png", width = 12, height = 6, dpi = 300)

# Filter to only years with multiple tales (cleaner)
productive_years <- emotion_by_year %>%
  filter(total_tales >= 3)  # Adjust threshold as needed

# Order the emotions in the chart so that disgust is on the bottom, then fear, then sadness, then anger, then neutral, then surprise, then joy.

emotion_order <- rev(c("disgust", "fear", "sadness", "anger", "neutral", "surprise", "joy"))

ggplot(productive_years, aes(x = factor(year), y = percentage, fill = factor(dominant_emotion, levels = emotion_order))) +
  geom_col(width = 0.8) +
  scale_fill_manual(values = emotion_colors) +
  labs(
    title = "Emotional Distribution in Productive Years",
    subtitle = paste("Years with 3+ tales (n =", n_distinct(productive_years$year), "years)"),
    x = "Year",
    y = "Percentage of Tales",
    fill = "Dominant Emotion"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )

ggsave("emotion_bar_chart.png", width = 14, height = 6, dpi = 300)

### HEATMAP
# Complete the data for all year/emotion combinations
heatmap_data <- emotion_by_year %>%
  complete(year = full_seq(year, 1), dominant_emotion, 
           fill = list(n = 0, percentage = 0, total_tales = 0))

ggplot(heatmap_data, aes(x = year, y = dominant_emotion, fill = n)) +
  geom_tile(color = "grey20", size = 0.5) +
  scale_fill_gradient(
    low = "#1a1a1a", 
    high = "#F8E71C",
    na.value = "grey10",
    name = "Tales"
  ) +
  labs(
    title = "Emotion Heatmap: Tale Count by Year",
    x = "Year",
    y = "Dominant Emotion"
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

ggsave("emotion_heatmap.png", width = 14, height = 6, dpi = 300)

# PROPORTIONAL BUBBLE
# Cool alternative - bubbles sized by tale count
ggplot(emotion_by_year, aes(x = year, y = dominant_emotion)) +
  geom_point(aes(size = n, color = dominant_emotion), alpha = 0.6) +
  scale_size_continuous(range = c(2, 15), name = "Tale Count") +
  scale_color_manual(values = emotion_colors) +
  labs(
    title = "Emotion Distribution Timeline",
    subtitle = "Bubble size = number of tales",
    x = "Year",
    y = "Dominant Emotion"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

ggsave("emotion_bubbles.png", width = 14, height = 6, dpi = 300)

```


# Manually add story AKA's

```{r}
# In R preprocessing
tale_aliases <- tribble(
  ~tale, ~aliases,
  "The Little Mermaid", "Mermaid, Little Mermaid",
  "The Ugly Duckling", "Duckling, Ugly Duckling",
  "The Little Match Girl", "Match Girl, Little Match Girl"
)

# Export to JSON
write_json(tale_aliases, "data/tale_aliases.json")
```

// In JS
async function loadAliases() {
  const aliases = await d3.json("data/tale_aliases.json");
  
  // Create reverse lookup
  aliasMap = new Map();
  aliases.forEach(({ tale, aliases }) => {
    const aliasList = aliases.split(',').map(a => a.trim().toLowerCase());
    aliasList.forEach(alias => aliasMap.set(alias, tale));
  });
}

// In search function
function searchWithAliases(query) {
  query = query.toLowerCase();
  
  // Direct match
  let matches = data.filter(d => d.tale.toLowerCase().includes(query));
  
  // Alias match
  if (aliasMap.has(query)) {
    const canonicalTale = aliasMap.get(query);
    const aliasMatches = data.filter(d => d.tale === canonicalTale);
    matches = [...matches, ...aliasMatches];
  }
  
  return [...new Set(matches)]; // Remove duplicates
}
```

---

## Recommended Page Structure
```
┌─────────────────────────────────────────────────┐
│  TITLE: Hans Christian Andersen's Tales         │
│  Subtitle: A Lifetime of Stories (1805-1875)   │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  SEARCH BAR                                      │
│  [Search tales...]  [Clear]                     │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  EMOTIONAL FLOW SECTION (Optional)              │
│  Stacked area chart showing emotion             │
│  distribution by year                           │
│  - Interactive (click year to filter below)     │
│  - Legend showing emotion colors                │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  MAIN TIMELINE                                   │
│  Your current stacked timeline with:            │
│  - Tales as circles/diamonds                    │
│  - Color by emotion                             │
│  - Size by length                               │
│  - Opacity by certainty                         │
│  - Biographical context bands                   │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  LEGEND                                          │
│  - Emotion colors                               │
│  - Shape meanings                               │
│  - Interaction instructions                     │
└─────────────────────────────────────────────────┘

Let's prepare potential clustering/similarity features for a "recommender" type system. A common problem in our current data is that stories can be as short as 1 "chunk" in length or as long as 48 chunks. What's a way to compare these two stories? 

A first pass will be low-hanging fruit; create summary statistics for each of the 7 emotions: min, mean, max, and sd which can be compared by some similarity algorithm (cosine? knn?).

Let's actually start with DTW just using the values we already have.

```{r}
library(dtw)

# Pure DTW comparison of emotional trajectories
calculate_dtw_emotion_similarity <- function(emotion_results, emotions_to_use = NULL) {
  
  if(is.null(emotions_to_use)) {
    emotions_to_use <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  }
  
  tales <- unique(emotion_results$tale)
  n_tales <- length(tales)
  
  # Initialize similarity matrix
  dtw_matrix <- matrix(0, nrow = n_tales, ncol = n_tales)
  rownames(dtw_matrix) <- tales
  colnames(dtw_matrix) <- tales
  
  cat("Calculating DTW similarities for", n_tales, "tales...\n")
  pb <- txtProgressBar(min = 0, max = n_tales * (n_tales - 1) / 2, style = 3)
  counter <- 0
  
  for(i in 1:n_tales) {
    for(j in i:n_tales) {
      
      if(i == j) {
        dtw_matrix[i, j] <- 1.0  # Perfect self-similarity
        next
      }
      
      # Get emotion trajectories for both stories
      story1_data <- emotion_results %>% 
        filter(tale == tales[i]) %>% 
        arrange(chunk) %>%
        select(all_of(emotions_to_use))
      
      story2_data <- emotion_results %>% 
        filter(tale == tales[j]) %>% 
        arrange(chunk) %>%
        select(all_of(emotions_to_use))
      
      if(nrow(story1_data) == 0 || nrow(story2_data) == 0) {
        dtw_matrix[i, j] <- dtw_matrix[j, i] <- 0
        next
      }
      
      # Calculate DTW distance for each emotion separately, then combine
      emotion_distances <- map_dbl(emotions_to_use, function(emotion) {
        
        seq1 <- story1_data[[emotion]]
        seq2 <- story2_data[[emotion]]
        
        # DTW alignment
        dtw_result <- dtw(seq1, seq2, 
                         distance.only = TRUE,
                         step.pattern = symmetric2)  # Allow flexible alignment
        
        return(dtw_result$distance)
      })
      
      # Combine distances across emotions (simple average)
      avg_distance <- mean(emotion_distances)
      
      # Convert distance to similarity (0-1 scale)
      # Using adaptive normalization based on sequence lengths
      max_possible_distance <- sqrt(sum(c(length(story1_data[[1]]), length(story2_data[[1]]))))
      similarity <- exp(-avg_distance / max_possible_distance)
      
      # Store symmetric similarity
      dtw_matrix[i, j] <- dtw_matrix[j, i] <- similarity
      
      counter <- counter + 1
      setTxtProgressBar(pb, counter)
    }
  }
  
  close(pb)
  return(dtw_matrix)
}

# Calculate DTW similarities
dtw_similarities <- calculate_dtw_emotion_similarity(emotion_results)

# Function to get recommendations based on DTW
recommend_by_dtw <- function(target_tale, dtw_matrix, n_recs = 5) {
  
  if(!target_tale %in% rownames(dtw_matrix)) {
    stop("Tale not found in similarity matrix")
  }
  
  # Get similarities for target tale
  similarities <- dtw_matrix[target_tale, ]
  
  # Remove self and sort
  similarities <- similarities[names(similarities) != target_tale]
  top_matches <- sort(similarities, decreasing = TRUE)[1:n_recs]
  
  # Create results with story length info for context
  recommendations <- tibble(
    recommended_tale = names(top_matches),
    dtw_similarity = as.numeric(top_matches),
    similarity_percent = round(as.numeric(top_matches) * 100, 1)
  ) %>%
    left_join(
      emotion_results %>% 
        group_by(tale) %>% 
        summarise(num_chunks = n(), .groups = "drop"),
      by = c("recommended_tale" = "tale")
    )
  
  return(recommendations)
}

# Test DTW recommendations
dtw_recs <- recommend_by_dtw("The ugly duckling", dtw_similarities)
recommend_by_dtw("\"Something\"", dtw_similarities)
print(dtw_recs)

# Plot both of the following stories' emotional trajectories on one Rstudio plot for comparison. We already have function plot_tale, can we use par(mfrow) or something similar?

par(mfrow = c(2, 1))  # 2 rows, 1 column


plot_tale("\"Something\"")
plot_tale("The shepherdess and the sweep")
```

Using other similarity measure for sanity and comparison

```{r}
# 1. Cosine similarity of raw emotion vectors (no temporal alignment)
calculate_cosine_similarity <- function(story1, story2, emotion_results) {
  
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  s1_data <- emotion_results %>% filter(tale == story1) %>% select(all_of(emotions))
  s2_data <- emotion_results %>% filter(tale == story2) %>% select(all_of(emotions))
  
  # Flatten to vectors
  s1_vec <- as.numeric(unlist(s1_data))
  s2_vec <- as.numeric(unlist(s2_data))
  
  # Pad shorter vector with means to make same length
  if(length(s1_vec) != length(s2_vec)) {
    if(length(s1_vec) < length(s2_vec)) {
      s1_vec <- c(s1_vec, rep(mean(s1_vec), length(s2_vec) - length(s1_vec)))
    } else {
      s2_vec <- c(s2_vec, rep(mean(s2_vec), length(s1_vec) - length(s2_vec)))
    }
  }
  
  # Cosine similarity
  cos_sim <- sum(s1_vec * s2_vec) / (sqrt(sum(s1_vec^2)) * sqrt(sum(s2_vec^2)))
  return(cos_sim)
}

# 2. Correlation of emotion profiles (average emotion levels)
calculate_profile_correlation <- function(story1, story2, emotion_results) {
  
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  s1_profile <- emotion_results %>% 
    filter(tale == story1) %>% 
    summarise(across(all_of(emotions), mean)) %>%
    unlist()
  
  s2_profile <- emotion_results %>% 
    filter(tale == story2) %>% 
    summarise(across(all_of(emotions), mean)) %>%
    unlist()
  
  return(cor(s1_profile, s2_profile))
}

# 3. Euclidean distance of emotion profiles
calculate_profile_distance <- function(story1, story2, emotion_results) {
  
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  s1_profile <- emotion_results %>% 
    filter(tale == story1) %>% 
    summarise(across(all_of(emotions), mean)) %>%
    unlist()
  
  s2_profile <- emotion_results %>% 
    filter(tale == story2) %>% 
    summarise(across(all_of(emotions), mean)) %>%
    unlist()
  
  euclidean_dist <- sqrt(sum((s1_profile - s2_profile)^2))
  # Convert to similarity (0-1 scale)
  return(exp(-euclidean_dist))
}

# Compare all methods for your example
compare_similarity_methods <- function(story1, story2, emotion_results) {
  
  cat("Similarity between '", story1, "' and '", story2, "':\n")
  cat("==================================================\n")
  
  # DTW similarity (from your existing matrix)
  dtw_sim <- dtw_similarities[story1, story2]
  cat("DTW Similarity:", round(dtw_sim, 3), "\n")
  
  # Cosine similarity
  cos_sim <- calculate_cosine_similarity(story1, story2, emotion_results)
  cat("Cosine Similarity:", round(cos_sim, 3), "\n")
  
  # Profile correlation
  prof_cor <- calculate_profile_correlation(story1, story2, emotion_results)
  cat("Profile Correlation:", round(prof_cor, 3), "\n")
  
  # Profile distance
  prof_dist <- calculate_profile_distance(story1, story2, emotion_results)
  cat("Profile Distance Similarity:", round(prof_dist, 3), "\n")
  
  cat("\n")
}

# Test on your example
compare_similarity_methods("\"Something\"", "The shepherdess and the sweep", emotion_results)

# Also test on a few other pairs for comparison
compare_similarity_methods("The ugly duckling", "The little mermaid", emotion_results)
```

Visual comparisons of methods

```{r}
# Create a visual comparison tool
create_comparison_plots <- function(story1, story2, emotion_results) {
  
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  # Get data
  s1_data <- emotion_results %>% 
    filter(tale == story1) %>% 
    arrange(chunk) %>%
    select(chunk, all_of(emotions)) %>%
    mutate(story = story1, position = row_number())
  
  s2_data <- emotion_results %>% 
    filter(tale == story2) %>% 
    arrange(chunk) %>%
    select(chunk, all_of(emotions)) %>%
    mutate(story = story2, position = row_number())
  
  # Combine and reshape
  plot_data <- bind_rows(s1_data, s2_data) %>%
    pivot_longer(all_of(emotions), names_to = "emotion", values_to = "intensity")
  
  # Plot 1: Side-by-side trajectories
  trajectory_plot <- ggplot(plot_data, aes(x = position, y = intensity, color = emotion)) +
    geom_line(linewidth = 1.2, alpha = 0.8) +
    geom_point(size = 2) +
    facet_wrap(~story, scales = "free_x", ncol = 1) +
    labs(
      title = paste("Emotional Trajectories Comparison"),
      subtitle = paste(story1, "vs", story2),
      x = "Position in Story",
      y = "Emotion Intensity"
    ) +
    theme_minimal() +
    scale_color_manual(values = c(
      "anger" = "#D0021B", "joy" = "#7ED321", "sadness" = "#4A90E2",
      "fear" = "#9013FE", "disgust" = "#F5A623", "surprise" = "#F8E71C", 
      "neutral" = "#9B9B9B"
    )) +
    theme(legend.position = "bottom")
  
  # Plot 2: Average emotion profiles
  profile_data <- plot_data %>%
    group_by(story, emotion) %>%
    summarise(avg_intensity = mean(intensity), .groups = "drop") %>%
    pivot_wider(names_from = story, values_from = avg_intensity) %>%
    rename(story1_avg = all_of(story1), story2_avg = all_of(story2))
  
  profile_plot <- ggplot(profile_data, aes(x = story1_avg, y = story2_avg)) +
    geom_point(aes(color = emotion), size = 4) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(aes(label = emotion), hjust = 1.1, size = 3) +
    labs(
      title = "Average Emotion Profile Comparison",
      x = paste("Average intensity in", story1),
      y = paste("Average intensity in", story2),
      subtitle = "Points near diagonal line = similar average levels"
    ) +
    theme_minimal() +
    scale_color_manual(values = c(
      "anger" = "#D0021B", "joy" = "#7ED321", "sadness" = "#4A90E2",
      "fear" = "#9013FE", "disgust" = "#F5A623", "surprise" = "#F8E71C", 
      "neutral" = "#9B9B9B"
    )) +
    theme(legend.position = "none")
  
  # Combine plots
  library(patchwork)
  combined_plot <- trajectory_plot / profile_plot
  
  print(combined_plot)
  return(invisible(combined_plot))
}

# Visualize your problematic pair
create_comparison_plots("\"Something\"", "The shepherdess and the sweep", emotion_results)
```

```{r}
# Weight emotions differently - maybe fear is dominating the similarity
calculate_weighted_dtw <- function(story1, story2, emotion_results, emotion_weights = NULL) {
  
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  # Default: reduce weight of dominant emotions to see other patterns
  if(is.null(emotion_weights)) {
    emotion_weights <- c(anger = 1, joy = 1, sadness = 1, fear = 0.5, 
                        disgust = 1, surprise = 1, neutral = 0.3)
  }
  
  s1_data <- emotion_results %>% filter(tale == story1) %>% arrange(chunk)
  s2_data <- emotion_results %>% filter(tale == story2) %>% arrange(chunk)
  
  weighted_distances <- map_dbl(emotions, function(emotion) {
    seq1 <- s1_data[[emotion]]
    seq2 <- s2_data[[emotion]]
    
    dtw_dist <- dtw(seq1, seq2, distance.only = TRUE)$distance
    return(dtw_dist * emotion_weights[emotion])
  })
  
  avg_weighted_distance <- mean(weighted_distances)
  max_possible <- sqrt(nrow(s1_data) + nrow(s2_data))
  
  similarity <- exp(-avg_weighted_distance / max_possible)
  return(similarity)
}

# Test with reduced fear weight
weighted_sim <- calculate_weighted_dtw("Something", "The shepherdess and the sweep", emotion_results)
cat("Weighted DTW similarity (reduced fear weight):", round(weighted_sim, 3), "\n")
```



```{r}
library(tidyverse)
library(proxy)  # for distance/similarity functions
library(corrplot)
library(factoextra)

# Create comprehensive statistical features for each story
create_story_features <- function(emotion_df) {
  
  # Define emotions to analyze
  emotions <- c("anger", "joy", "sadness", "fear", "disgust", "surprise", "neutral")
  
  story_features <- emotion_df %>%
    group_by(tale) %>%
    summarise(
      # Story metadata
      num_chunks = n(),
      total_tokens = sum(token_count, na.rm = TRUE),
      avg_chunk_size = mean(token_count, na.rm = TRUE),
      
      # Statistical features for each emotion
      across(all_of(emotions), list(
        mean = ~mean(.x, na.rm = TRUE),
        sd = ~sd(.x, na.rm = TRUE),
        min = ~min(.x, na.rm = TRUE),
        max = ~max(.x, na.rm = TRUE),
        q25 = ~quantile(.x, 0.25, na.rm = TRUE),
        q75 = ~quantile(.x, 0.75, na.rm = TRUE),
        range = ~max(.x, na.rm = TRUE) - min(.x, na.rm = TRUE),
        cv = ~sd(.x, na.rm = TRUE) / mean(.x, na.rm = TRUE),  # coefficient of variation
        skew = ~moments::skewness(.x, na.rm = TRUE),
        kurtosis = ~moments::kurtosis(.x, na.rm = TRUE)
      ), .names = "{.col}_{.fn}"),
      
      # Emotional trajectory features (slopes)
      across(all_of(emotions), list(
        slope = ~if(n() > 1) coef(lm(.x ~ chunk))[2] else 0,
        slope_pval = ~if(n() > 1) summary(lm(.x ~ chunk))$coefficients[2,4] else 1
      ), .names = "{.col}_{.fn}"),
      
      # Dominant emotion consistency
      dominant_emotion_mode = names(sort(table(dominant_emotion), decreasing = TRUE))[1],
      dominant_consistency = max(table(dominant_emotion)) / n(),
      
      # Emotional complexity measures
      emotion_entropy = -sum(sapply(emotions, function(e) {
        p <- mean(get(e), na.rm = TRUE)
        if(p > 0) p * log(p) else 0
      })),
      
      # Emotional variability (how much emotions change)
      total_emotion_variance = sum(sapply(emotions, function(e) var(get(e), na.rm = TRUE))),
      
      # Story arc features
      beginning_intensity = if(n() >= 3) mean(c(anger[1], fear[1], sadness[1]), na.rm = TRUE) else NA,
      middle_intensity = if(n() >= 3) {
        mid_start <- ceiling(n()/3)
        mid_end <- floor(2*n()/3)
        mean(c(anger[mid_start:mid_end], fear[mid_start:mid_end], sadness[mid_start:mid_end]), na.rm = TRUE)
      } else NA,
      end_intensity = if(n() >= 3) mean(c(anger[n()], fear[n()], sadness[n()]), na.rm = TRUE) else NA
      
    ) %>%
    ungroup() %>%
    # Create additional derived features
    mutate(
      # Emotional arc classification
      arc_pattern = case_when(
        is.na(beginning_intensity) | is.na(end_intensity) ~ "Single_Chunk",
        end_intensity > beginning_intensity + 0.1 ~ "Rising_Tension",
        beginning_intensity > end_intensity + 0.1 ~ "Tension_Resolution", 
        abs(middle_intensity - beginning_intensity) > 0.1 & 
        abs(end_intensity - beginning_intensity) < 0.05 ~ "Journey_Return",
        TRUE ~ "Steady_State"
      ),
      
      # Positive vs negative emotional balance
      positive_balance = (joy_mean + surprise_mean) - (anger_mean + sadness_mean + fear_mean + disgust_mean),
      emotional_intensity = 1 - neutral_mean,
      
      # Length categories for comparison
      length_category = case_when(
        num_chunks == 1 ~ "Single",
        num_chunks <= 5 ~ "Short", 
        num_chunks <= 15 ~ "Medium",
        TRUE ~ "Long"
      )
    )
  
  return(story_features)
}

# Apply the function
story_features <- create_story_features(emotion_results)

# Display summary
cat("Created", ncol(story_features), "features for", nrow(story_features), "stories\n")
glimpse(story_features)

story_features %>% view()
```

